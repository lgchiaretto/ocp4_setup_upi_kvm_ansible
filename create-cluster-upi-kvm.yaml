- name: Create clusters UPI on KVM
  hosts: localhost
  become_method: sudo

  vars:
    mirror_url: "https://mirror.openshift.com/pub/openshift-v4/x86_64/dependencies/rhcos/"
    start_time: "{{ lookup('pipe', 'date +%s') }}"
    ansible_ssh_private_key_file: "~/.ssh/id_rsa"
    ansible_ssh_common_args: "-o StrictHostKeyChecking=no"

  tasks:
    - name: Collect the start time
      ansible.builtin.set_fact:
        start_time: "{{ lookup('pipe', 'date +%s') }}"

    - name: Check if ocp version is valid
      ansible.builtin.uri:
        url: "https://mirror.openshift.com/pub/openshift-v4/clients/ocp/{{ ocpversion }}/openshift-client-linux.tar.gz"
        method: HEAD
        status_code: 200
      register: result
      ignore_errors: true

    - name: Fail if ocpversion is not valid
      ansible.builtin.fail:
        msg: "The 'ocpversion' variable is not a valid version!"
      when: result.status != 200

    - name: Ensure necessary packages are installed
      ansible.builtin.yum:
        name:
          - qemu-kvm
          - libvirt
          - virt-install
          - virt-manager
          - guestfs-tools
          - python3-pip
          - coreos-installer
        state: present
      become: true

    - name: Ensure libvirtd service is running
      ansible.builtin.service:
        name: libvirtd
        state: started
        enabled: true
      become: true

    - name: Get a list of all virtual machines
      ansible.builtin.command: virsh list --all --name
      register: vms
      changed_when: vms.rc == 0
      become: true
      when: destroy_if_exists == "true"

    - name: Filter VMs containing 'clustername' in their names
      ansible.builtin.set_fact:
        allvms: "{{ vms.stdout_lines | select('search', clustername) }}"
      when: destroy_if_exists == "true"

    - name: Destroy all vms
      community.libvirt.virt:
        command: destroy
        force: true
        name: "{{ item }}"
      loop: "{{ allvms }}"
      ignore_errors: true
      become: true
      when: destroy_if_exists == "true"

    - name: Undefine all vms
      community.libvirt.virt:
        command: undefine
        force: true
        name: "{{ item }}"
      loop: "{{ allvms }}"
      ignore_errors: true
      become: true
      when: destroy_if_exists == "true"

    - name: Delete all network files
      ansible.builtin.file:
        path: "{{ item }}"
        state: absent
      register: deletefiles
      with_items:
        - "/etc/NetworkManager/dnsmasq.d/{{ clustername }}.conf"
        - "/etc/dnsmasq.{{ clustername }}.addnhosts"
        - "/{{ clusters_dir }}/{{ clustername }}/"
      become: true
      when: destroy_if_exists == "true"

    - name: Configuring networkmanager to use dnsmasq
      ansible.builtin.copy:
        dest: "/etc/NetworkManager/conf.d/nm-dns.conf"
        content: |
          [main]
          dns=dnsmasq
      register: configdnsmasq
      become: true

    - name: Stop systemd-resolved service
      ansible.builtin.systemd:
        name: systemd-resolved
        state: stopped
        enabled: false
      become: true
      when: ansible_facts['distribution'] == 'Fedora'

    - name: Disable systemd-resolved from starting at boot
      ansible.builtin.systemd:
        name: systemd-resolved
        enabled: false
      become: true
      when: ansible_facts['distribution'] == 'Fedora'

    - name: Remove /etc/resolv.conf
      ansible.builtin.file:
        path: /etc/resolv.conf
        state: absent
      when: ansible_facts['distribution'] == 'Fedora'
      become: true

    - name: Restart Network Manager when configuring dnsmasq
      ansible.builtin.service:
        name: NetworkManager
        state: restarted
      become: true

    - name: Sleeping 5 seconds to wait NetworkManager
      ansible.builtin.pause:
        seconds: 5

    - name: Ensure 'kubernetes' Python package is installed
      ansible.builtin.pip:
        name: "{{ item }}"
        state: present
        executable: pip
      with_items:
        - kubernetes
        - passlib

    - name: Ensure libvirtd service is running
      ansible.builtin.service:
        name: libvirtd
        state: started
        enabled: true
      become: true

    - name: Create the OCP version cache directory if it does not exist
      ansible.builtin.file:
        path: "{{ clusters_dir }}/.cache/{{ ocpversion | regex_replace('(\\d+\\.\\d+).*', '\\1') }}/"
        state: directory
        mode: '0755'
        owner: "{{ lookup('env', 'USER') }}"
      become: true

    - name: Check if the installer file already exists on cache
      ansible.builtin.stat:
        path: "{{ clusters_dir }}/.cache/{{ ocpversion | regex_replace('(\\d+\\.\\d+).*', '\\1') }}/openshift-install-linux-{{ ocpversion }}.tar.gz"
      register: installfile

    - name: Download installer openshift-install-linux.tar.gz to cache
      ansible.builtin.get_url:
        url: "https://mirror.openshift.com/pub/openshift-v4/clients/ocp/{{ ocpversion }}/openshift-install-linux.tar.gz"
        dest: "{{ clusters_dir }}/.cache/{{ ocpversion | regex_replace('(\\d+\\.\\d+).*', '\\1') }}/openshift-install-linux-{{ ocpversion }}.tar.gz"
        mode: '0644'
        owner: "{{ lookup('env', 'USER') }}"
      become: true
      when: installfile.stat is defined and not installfile.stat.exists

    - name: Check if rhcos.iso file already exists on cache
      ansible.builtin.stat:
        path: "{{ clusters_dir }}/.cache/{{ ocpversion | regex_replace('(\\d+\\.\\d+).*', '\\1') }}/rhcos.iso"
      register: rhcosisofile

    - name: Download rhcos iso to cache when ocp <= 4.18
      ansible.builtin.get_url:
        url: "https://mirror.openshift.com/pub/openshift-v4/x86_64/dependencies/rhcos/{{ ocpversion | regex_replace('(\\d+\\.\\d+).*', '\\1') }}/latest/rhcos-live.x86_64.iso"
        dest: "{{ clusters_dir }}/.cache/{{ ocpversion | regex_replace('(\\d+\\.\\d+).*', '\\1') }}/rhcos.iso"
        mode: '0644'
        owner: "{{ lookup('env', 'USER') }}"
      become: true
      when:
        - rhcosisofile.stat is defined
        - not rhcosisofile.stat.exists
        - (not "4.19" in ocpversion)

    - name: Download rhcos iso to cache when ocp >= 4.19
      ansible.builtin.get_url:
        url: "https://mirror.openshift.com/pub/openshift-v4/x86_64/dependencies/rhcos/{{ ocpversion | regex_replace('(\\d+\\.\\d+).*', '\\1') }}/latest/rhcos-live-iso.x86_64.iso"
        dest: "{{ clusters_dir }}/.cache/{{ ocpversion | regex_replace('(\\d+\\.\\d+).*', '\\1') }}/rhcos.iso"
        mode: '0644'
        owner: "{{ lookup('env', 'USER') }}"
      become: true
      when:
        - rhcosisofile.stat is defined
        - not rhcosisofile.stat.exists
        - ("4.19" in ocpversion)

    - name: Check if the RHCOS file already exists on cache
      ansible.builtin.stat:
        path: "{{ clusters_dir }}/.cache/{{ ocpversion | regex_replace('(\\d+\\.\\d+).*', '\\1') }}/rhcos-qemu.x86_64.qcow2"
      register: rhcosfile
      when: sno == "false"

    - name: Check if the initramfs file already exists on cache
      ansible.builtin.stat:
        path: "{{ clusters_dir }}/.cache/{{ ocpversion | regex_replace('(\\d+\\.\\d+).*', '\\1') }}/initramfs.img"
      register: initramfsfile
      when: sno == "false"

    - name: Check if the rhcos-live-kernel-x86_64 file already exists on cache
      ansible.builtin.stat:
        path: "{{ clusters_dir }}/.cache/{{ ocpversion | regex_replace('(\\d+\\.\\d+).*', '\\1') }}/vmlinuz"
      register: kernelfile
      when: sno == "false"

    - name: Check if the rhcos-live-rootfs.x86_64.img file already exists on cache
      ansible.builtin.stat:
        path: "{{ clusters_dir }}/.cache/{{ ocpversion | regex_replace('(\\d+\\.\\d+).*', '\\1') }}/rhcos-live-rootfs.x86_64.img"
      register: rootfsfile
      when: sno == "false"

    - name: Download RHCOS images
      ansible.builtin.get_url:
        url: "{{ mirror_url }}{{ ocpversion | regex_replace('(\\d+\\.\\d+).*', '\\1') }}/latest/rhcos-qemu.x86_64.qcow2.gz"
        dest: "{{ clusters_dir }}/.cache/{{ ocpversion | regex_replace('(\\d+\\.\\d+).*', '\\1') }}/rhcos-qemu.x86_64.qcow2.gz"
        mode: "0644"
      when: rhcosfile.stat is defined and not rhcosfile.stat.exists and sno == "false"

    - name: Download rootfs file
      ansible.builtin.get_url:
        url: "{{ mirror_url }}{{ ocpversion | regex_replace('(\\d+\\.\\d+).*', '\\1') }}/latest/rhcos-live-rootfs.x86_64.img"
        dest: "{{ clusters_dir }}/.cache/{{ ocpversion | regex_replace('(\\d+\\.\\d+).*', '\\1') }}/rhcos-live-rootfs.x86_64.img"
        mode: "0644"
      when: rootfsfile.stat is defined and not rootfsfile.stat.exists and sno == "false"

    - name: Download initramfs images
      ansible.builtin.get_url:
        url: "{{ mirror_url }}{{ ocpversion | regex_replace('(\\d+\\.\\d+).*', '\\1') }}/latest/rhcos-live-initramfs.x86_64.img"
        dest: "{{ clusters_dir }}/.cache/{{ ocpversion | regex_replace('(\\d+\\.\\d+).*', '\\1') }}/initramfs.img"
        mode: "0644"
      when: initramfsfile.stat is defined and not initramfsfile.stat.exists and sno == "false"

    - name: Download rhcos-live-kernel-x86_64 images
      ansible.builtin.get_url:
        url: "{{ mirror_url }}{{ ocpversion | regex_replace('(\\d+\\.\\d+).*', '\\1') }}/latest/rhcos-live-kernel.x86_64"
        dest: "{{ clusters_dir }}/.cache/{{ ocpversion | regex_replace('(\\d+\\.\\d+).*', '\\1') }}/vmlinuz"
        mode: "0644"
      when: kernelfile.stat is defined and not kernelfile.stat.exists and sno == "false"

    - name: Create cluster directory
      ansible.builtin.file:
        path: "{{ clusters_dir }}/{{ clustername }}"
        state: "directory"
        mode: "0755"
        owner: "{{ lookup('env', 'USER') }}"
      become: true

    - name: Create rhcos-install directory directory
      ansible.builtin.file:
        path: "{{ clusters_dir }}/{{ clustername }}/rhcos-install"
        state: "directory"
        mode: "0755"
      when: sno == "false"

    - name: Copy openshift-install.tar.gz to cluster dir
      ansible.builtin.copy:
        remote_src: true
        src: "{{ clusters_dir }}/.cache/{{ ocpversion | regex_replace('(\\d+\\.\\d+).*', '\\1') }}/openshift-install-linux-{{ ocpversion }}.tar.gz"
        dest: "{{ clusters_dir }}/{{ clustername }}/"
        mode: '0644'

    - name: Untar on openshift-install-linux.tar.gz file
      ansible.builtin.unarchive:
        remote_src: true
        src: "{{ clusters_dir }}/{{ clustername }}/openshift-install-linux-{{ ocpversion }}.tar.gz"
        dest: "{{ clusters_dir }}/{{ clustername }}"

    - name: Copy rhcos.iso to cluster dir to master
      ansible.builtin.copy:
        remote_src: true
        src: "{{ clusters_dir }}/.cache/{{ ocpversion | regex_replace('(\\d+\\.\\d+).*', '\\1') }}/rhcos.iso"
        dest: "{{ clusters_dir }}/{{ clustername }}/rhcos-master.iso"
        mode: '0644'
      when: sno == "true"

    - name: Copy rhcos.iso to cluster dir to worker
      ansible.builtin.copy:
        remote_src: true
        src: "{{ clusters_dir }}/.cache/{{ ocpversion | regex_replace('(\\d+\\.\\d+).*', '\\1') }}/rhcos.iso"
        dest: "{{ clusters_dir }}/{{ clustername }}/rhcos-worker.iso"
        mode: '0644'

    - name: Copy install-config.yaml
      ansible.builtin.template:
        src: install-config.yaml-upi.j2
        dest: "{{ clusters_dir }}/{{ clustername }}/install-config.yaml"
        mode: '0644'

    - name: Copy files to rhcos-install directory
      ansible.builtin.copy:
        remote_src: true
        src: "{{ clusters_dir }}/.cache/{{ ocpversion | regex_replace('(\\d+\\.\\d+).*', '\\1') }}/{{ item }}"
        dest: "{{ clusters_dir }}/{{ clustername }}/rhcos-install/"
        mode: '0644'
      with_items:
        - vmlinuz
        - initramfs.img
        - rhcos-qemu.x86_64.qcow2.gz
        - rhcos-live-rootfs.x86_64.img
      when: sno == "false"

    - name: Extract RHCOS image
      ansible.builtin.command: "gunzip -f -d {{ clusters_dir }}/{{ clustername }}/rhcos-install/rhcos-qemu.x86_64.qcow2.gz"
      register: extractdfile
      changed_when: extractdfile.rc == 0
      when: sno == "false"

    - name: Resizing RHCOS image
      ansible.builtin.command: "qemu-img resize {{ clusters_dir }}/{{ clustername }}/rhcos-install/rhcos-qemu.x86_64.qcow2 120G"
      register: resizeqcow2
      changed_when: resizeqcow2.rc == 0
      when: sno == "false"

    - name: Create treeinfo file
      ansible.builtin.template:
        src: treeinfo.j2
        dest: "{{ clusters_dir }}/{{ clustername }}/rhcos-install/.treeinfo"
        mode: '0644'
      when: sno == "false"

    - name: Create tmpws.service file
      ansible.builtin.template:
        src: tmpws.service.j2
        dest: "{{ clusters_dir }}/{{ clustername }}/tmpws.service"
        mode: '0644'
      when: sno == "false"

    - name: Create ssh file
      ansible.builtin.copy:
        remote_src: true
        content: "{{ ssh_rsa }}"
        dest: "{{ clusters_dir }}/{{ clustername }}/id_rsa.pub"
        mode: '0644'
      when: sno == "false"

    - name: Run create manifests files when not sno
      ansible.builtin.command: "./openshift-install create manifests"
      args:
        chdir: "{{ clusters_dir }}/{{ clustername }}"
      register: manifests
      changed_when: true
      when: sno == "false"

    - name: Creating manifests for LSO and ODF namespaces
      ansible.builtin.template:
        dest: "{{ clusters_dir }}/{{ clustername }}/openshift/98_{{ item }}.yaml"
        mode: '0644'
        src: "{{ item }}.yaml.j2"
      loop:
        - local-storage-namespace
        - odf-namespace
      when: installodf == "true" and sno == "false"

    - name: Creating manifests for LSO and ODF operators
      ansible.builtin.template:
        dest: "{{ clusters_dir }}/{{ clustername }}/openshift/99_{{ item }}.yaml"
        mode: '0644'
        src: "{{ item }}.yaml.j2"
      loop:
        - local-storage-subscription
        - local-storage-operatorgroup
        - odf-subscription
        - odf-operatorgroup
      when: installodf == "true" and sno == "false"

    - name: Creating manifests for OCP Virt operator namespace
      ansible.builtin.template:
        dest: "{{ clusters_dir }}/{{ clustername }}/openshift/98_ocpvirt-namespace.yaml"
        mode: '0644'
        src: "ocpvirt-namespace.yaml.j2"
      when: installodf == "true" and installocpvirt == "true" and sno == "false"

    - name: Creating manifests for OCP Virt operator
      ansible.builtin.template:
        dest: "{{ clusters_dir }}/{{ clustername }}/openshift/99_{{ item }}.yaml"
        mode: '0644'
        src: "{{ item }}.yaml.j2"
      loop:
        - ocpvirt-subscription
        - ocpvirt-operatorgroup
      when: installodf == "true"  and installocpvirt == "true" and sno == "false"

    - name: Run create single-node-ignition-config files
      ansible.builtin.command: "./openshift-install create single-node-ignition-config"
      args:
        chdir: "{{ clusters_dir }}/{{ clustername }}"
      register: install
      changed_when: true
      when: sno == "true"

    - name: Run create ignition files
      ansible.builtin.command: "./openshift-install create ignition-configs"
      args:
        chdir: "{{ clusters_dir }}/{{ clustername }}"
      register: install
      changed_when: true
      when: sno == "false"

    - name: Add bootstrap.ign to rhcos-master.iso
      ansible.builtin.command: "coreos-installer iso ignition embed -fi bootstrap-in-place-for-live-iso.ign rhcos-master.iso"
      args:
        chdir: "{{ clusters_dir }}/{{ clustername }}"
      register: rhcosmaster
      changed_when: true
      when: sno == "true"

    - name: Add worker.ign to rhcos-worker.iso
      ansible.builtin.command: "coreos-installer iso ignition embed -fi worker.ign rhcos-worker.iso"
      args:
        chdir: "{{ clusters_dir }}/{{ clustername }}"
      register: rhcosworker
      changed_when: true

    - name: Customize LB for OpenShift nodes (could take long time)
      ansible.builtin.command: virt-builder fedora-40 --format qcow2 --cache {{ clusters_dir }}/.cache/ --size 10G -o "lb.qcow2" \
                              --firstboot-command "nmcli con mod 'Wired connection 1' connection.id enp1s0" \
                              --firstboot-command "sed -i 's/SELINUX=enforcing/SELINUX=disabled/' /etc/selinux/config" \
                              --firstboot-command "systemctl disable firewalld" \
                              --firstboot-command "setenforce 0" \
                              --firstboot-command "reboot" \
                              --ssh-inject "root:file:{{ clusters_dir }}/{{ clustername }}/id_rsa.pub" --selinux-relabel \
                              --copy-in bootstrap.ign:/opt/ --copy-in master.ign:/opt/ --copy-in worker.ign:/opt/ \
                              --copy-in tmpws.service:/etc/systemd/system/ \
                              --hostname "lb-{{ clustername }}.{{ basedomain }}" \
                              --install haproxy \
                              --copy-in rhcos-install/rhcos-live-rootfs.x86_64.img:/opt/ \
                              --copy-in rhcos-install/initramfs.img:/opt/ \
                              --copy-in rhcos-install/vmlinuz:/opt/ \
                              --copy-in rhcos-install/.treeinfo:/opt/ \
                              --run-command "systemctl daemon-reload" \
                              --run-command "systemctl enable tmpws.service" \
                              --run-command "systemctl enable haproxy.service" \
                              --root-password password:"{{ htpasswd_pass }}"
      register: customizelb
      args:
        chdir: "{{ clusters_dir }}/{{ clustername }}"
      changed_when: customizelb.rc == 0
      when: sno == "false"

    - name: Define and start LB
      ansible.builtin.command: virt-install --import --name {{ clustername }}-lb --disk "lb.qcow2" \
                              --memory 1024 --cpu host --vcpus 4 --os-variant rhel9-unknown --network network={{ kvmnetwork }},model=virtio \
                              --noautoconsole --autostart
      register: definelb
      become: true
      args:
        chdir: "{{ clusters_dir }}/{{ clustername }}"
      changed_when: definelb.rc == 0
      when: sno == "false"

    - name: Wait for lb to get mac address
      ansible.builtin.shell: "virsh dumpxml {{ clustername }}-lb | grep 'mac address' | sed \"s/.*mac address='\\([^']*\\)'.*/\\1/\""
      register: lb_info
      until: lb_info is defined and lb_info.stdout != ""
      retries: "180"
      delay: "1"
      become: true
      changed_when: true
      when: sno == "false"

    - name: Wait for the lb VM to get an IP address
      ansible.builtin.shell: "virsh domifaddr {{ clustername }}-lb | grep ipv4 | awk '{print $4}' | cut -d'/' -f1"
      retries: "180"
      delay: "3"
      until: lbvip.stdout is defined and lbvip.stdout != ""
      register: lbvip
      become: true
      changed_when: true
      when: sno == "false"

    - name: Create virtual machines disks when SNO
      block:
        - name: Create primary disk
          ansible.builtin.command: "qemu-img create -f qcow2 {{ clustername }}-master-0.qcow2 120G"
          args:
            chdir: "{{ clusters_dir }}/{{ clustername }}"
          register: qcow2master
          changed_when: true
        - name: Create extra disks
          ansible.builtin.command: "qemu-img create -f qcow2 {{ clustername }}-extra-disk-{{ item }}.qcow2 {{ extra_disk_size }}G"
          args:
            chdir: "{{ clusters_dir }}/{{ clustername }}"
          loop: "{{ range(1, extra_disks + 1) }}"
          when: extra_disks > 0
          register: extra_disks_result
          changed_when: true
      when: sno == "true"

    - name: Create virtual machines disks when 3 node cluster
      ansible.builtin.copy:
        remote_src: true
        src: "{{ clusters_dir }}/{{ clustername }}/rhcos-install/rhcos-qemu.x86_64.qcow2"
        dest: "{{ clusters_dir }}/{{ clustername }}/{{ item }}.qcow2"
      with_items:
        - "bootstrap"
        - "master-0"
        - "master-1"
        - "master-2"
      when: sno == "false"

    - name: Create extra disks on masters when installodf is true
      ansible.builtin.command: "qemu-img create -o preallocation=falloc -f qcow2 {{ clustername }}-{{ item }}-extra-disk.qcow2 {{ extra_disk_size }}G"
      args:
        chdir: "{{ clusters_dir }}/{{ clustername }}"
      loop:
        - "master-0"
        - "master-1"
        - "master-2"
      register: extra_disks_result
      become: true
      changed_when: true
      when: installodf == "true" and sno == "false"

    - name: Create worker disks
      ansible.builtin.command: "qemu-img create -f qcow2 {{ clustername }}-worker-{{ item }}.qcow2 120G"
      args:
        chdir: "{{ clusters_dir }}/{{ clustername }}"
      with_sequence: count={{ n_worker }} start=0
      changed_when: true
      when: n_worker != 0

    - name: Define bootstrap
      ansible.builtin.command: virt-install --name {{ clustername }}-bootstrap \
            --disk {{ clusters_dir }}/{{ clustername }}/bootstrap.qcow2,bus=virtio,size=120 \
            --ram "16000" --cpu host --vcpus "8" --os-variant rhel9-unknown --pxe --network network={{ kvmnetwork }},model=virtio \
            --location rhcos-install/ --noautoconsole \
            --extra-args 'nomodeset rd.neednet=1 coreos.inst=yes coreos.inst.install_dev=vda \
            coreos.live.rootfs_url=http://{{ lbvip.stdout_lines | first }}:1234/rhcos-live-rootfs.x86_64.img \
            coreos.inst.ignition_url=http://{{ lbvip.stdout_lines | first }}:1234/bootstrap.ign'
      register: bootstrapnodes
      become: true
      args:
        chdir: "{{ clusters_dir }}/{{ clustername }}"
      changed_when: bootstrapnodes.rc == 0
      when: sno == "false"

    - name: Wait for the bootstrap VM to get an IP address
      ansible.builtin.shell: "virsh domifaddr {{ clustername }}-bootstrap | grep ipv4 | awk '{print $4}' | cut -d'/' -f1"
      retries: "180"
      delay: "3"
      until: bootstrapip.stdout is defined and bootstrapip.stdout != ""
      register: bootstrapip
      become: true
      changed_when: true
      when: sno == "false"

    - name: Create cluster network conf on dnsmasq when not SNO
      ansible.builtin.template:
        src: "cluster-network.conf.j2"
        dest: "/etc/NetworkManager/dnsmasq.d/{{ clustername }}.conf"
        mode: '0644'
        selevel: s0
        serole: object_r
        setype: dnsmasq_etc_t
        seuser: system_u
      register: dnsmasqsno
      become: true
      when: sno == "false"

    - name: Create addnhosts file when not SNO
      ansible.builtin.template:
        src: "dnsmasq.openshift.addnhosts-bootstrap.j2"
        dest: "/etc/dnsmasq.{{ clustername }}.addnhosts"
        mode: '0644'
      register: addnhosts
      become: true
      when: sno == "false"

    - name: Restart Network Manager when configuring dnsmasq when not SNO
      ansible.builtin.service:
        name: NetworkManager
        state: restarted
      become: true
      when: sno == "false" and dnsmasqsno.changed

    - name: Restart libvirt when configuring dnsmasq when not SNO
      ansible.builtin.service:
        name: libvirtd
        state: restarted
      become: true
      when: sno == "false" and dnsmasqsno.changed

    - name: Define KVM VMs when SNO
      ansible.builtin.command: virt-install --import --name {{ clustername }}-master-0   \
            --disk {{ clusters_dir }}/{{ clustername }}/{{ clustername }}-master-0.qcow2,bus=virtio,size=120 \
            --disk {{ clusters_dir }}/{{ clustername }}/rhcos-master.iso,device=cdrom \
            {% for i in range(1, extra_disks + 1) %}
            --disk {{ clusters_dir }}/{{ clustername }}/{{ clustername }}-extra-disk-{{ i }}.qcow2,bus=virtio,size={{ extra_disk_size }} \
            {% endfor %}
            --boot hd,cdrom --check path_in_use=off --noreboot --noautoconsole \
            --ram "{{ master_mem }}" --cpu host --vcpus "{{ master_cpu }}" --os-variant rhel9-unknown --network network={{ kvmnetwork }},model=virtio
      register: createnodes
      become: true
      args:
        chdir: "{{ clusters_dir }}/{{ clustername }}"
      changed_when: createnodes.rc == 0
      when: sno == "true"

    - name: Starting virtual machines when SNO
      ansible.builtin.command: "virsh start {{ clustername }}-{{ item }}"
      register: startsnovms
      changed_when: startsnovms.rc == 0
      become: true
      with_items:
        - "master-0"
      when: sno == "true"

    - name: Define KVM masters on 3 node cluster
      ansible.builtin.command: virt-install --name {{ clustername }}-{{ item }} \
            --disk {{ clusters_dir }}/{{ clustername }}/{{ item}}.qcow2,bus=virtio,size=120 \
            --ram "{{ master_mem }}" --cpu host --vcpus "{{ master_cpu }}" --os-variant rhel9-unknown --pxe --network network={{ kvmnetwork }},model=virtio \
            --location rhcos-install/ --noautoconsole \
            --extra-args 'nomodeset rd.neednet=1 coreos.inst=yes coreos.inst.install_dev=vda \
            coreos.live.rootfs_url=http://{{ lbvip.stdout_lines | first }}:1234/rhcos-live-rootfs.x86_64.img \
            coreos.inst.ignition_url=http://{{ lbvip.stdout_lines | first }}:1234/master.ign'
      register: createnodes
      become: true
      args:
        chdir: "{{ clusters_dir }}/{{ clustername }}"
      changed_when: createnodes.rc == 0
      with_items:
        - "master-0"
        - "master-1"
        - "master-2"
      when: sno == "false"

    - name: Wait for master0 to get mac address when SNO
      ansible.builtin.shell: "virsh dumpxml {{ clustername }}-master-0 | grep 'mac address' | sed \"s/.*mac address='\\([^']*\\)'.*/\\1/\""
      register: master0infosno
      until: master0infosno is defined and master0infosno.stdout != ""
      retries: "180"
      delay: "1"
      become: true
      changed_when: true
      when: sno == "true"

    - name: Wait for master0 to get mac address when not SNO
      ansible.builtin.shell: "virsh dumpxml {{ clustername }}-master-0 | grep 'mac address' | sed \"s/.*mac address='\\([^']*\\)'.*/\\1/\""
      register: master0info
      until: master0info is defined and master0info.stdout != ""
      retries: "180"
      delay: "1"
      become: true
      changed_when: true
      when: sno == "false"


    - name: Wait for master1 to get mac address
      ansible.builtin.shell: "virsh dumpxml {{ clustername }}-master-1 | grep 'mac address' | sed \"s/.*mac address='\\([^']*\\)'.*/\\1/\""
      register: master1info
      until: master1info is defined and master1info.stdout != ""
      retries: "180"
      delay: "1"
      become: true
      changed_when: true
      when: sno == "false"

    - name: Wait for master2 to get mac address
      ansible.builtin.shell: "virsh dumpxml {{ clustername }}-master-2 | grep 'mac address' | sed \"s/.*mac address='\\([^']*\\)'.*/\\1/\""
      register: master2info
      until: master2info is defined and master2info.stdout != ""
      retries: "180"
      delay: "1"
      become: true
      changed_when: true
      when: sno == "false"

    - name: Wait for the master-0 VM to get an IP address
      ansible.builtin.shell: "virsh domifaddr {{ clustername }}-master-0 | grep ipv4 | awk '{print $4}' | cut -d'/' -f1"
      retries: "180"
      delay: "3"
      until: master0ip.stdout is defined and master0ip.stdout != ""
      register: master0ip
      become: true
      changed_when: true

    - name: Wait for the master-1 VM to get an IP address
      ansible.builtin.shell: "virsh domifaddr {{ clustername }}-master-1 | grep ipv4 | awk '{print $4}' | cut -d'/' -f1"
      retries: "180"
      delay: "3"
      until: master1ip.stdout is defined and master1ip.stdout != ""
      register: master1ip
      become: true
      changed_when: true
      when: sno == "false"

    - name: Wait for the master-2 VM to get an IP address
      ansible.builtin.shell: "virsh domifaddr {{ clustername }}-master-2 | grep ipv4 | awk '{print $4}' | cut -d'/' -f1"
      retries: "180"
      delay: "3"
      until: master2ip.stdout is defined and master2ip.stdout != ""
      register: master2ip
      become: true
      changed_when: true
      when: sno == "false"

    - name: Create cluster network conf on dnsmasq when SNO
      ansible.builtin.template:
        src: "cluster-network.conf-sno.j2"
        dest: "/etc/NetworkManager/dnsmasq.d/{{ clustername }}.conf"
        mode: '0644'
        selevel: s0
        serole: object_r
        setype: dnsmasq_etc_t
        seuser: system_u
      register: dnsmasq
      become: true
      when: sno == "true"

    - name: Create cluster network conf on dnsmasq when not SNO
      ansible.builtin.template:
        src: "cluster-network.conf-sno.j2"
        dest: "/etc/NetworkManager/dnsmasq.d/{{ clustername }}.conf"
        mode: '0644'
        selevel: s0
        serole: object_r
        setype: dnsmasq_etc_t
        seuser: system_u
      register: dnsmasq
      become: true
      when: sno == "false"

    - name: Create addnhosts file when not SNO
      ansible.builtin.template:
        src: "dnsmasq.openshift.addnhosts.j2"
        dest: "/etc/dnsmasq.{{ clustername }}.addnhosts"
        mode: '0644'
      register: addnhosts
      become: true
      when: sno == "false"

    - name: Create addnhosts file when SNO
      ansible.builtin.template:
        src: "dnsmasq.openshift.addnhosts-sno.j2"
        dest: "/etc/dnsmasq.{{ clustername }}.addnhosts"
        mode: '0644'
      register: addnhosts
      become: true
      when: sno == "true"

    - name: Restart Network Manager when configuring dnsmasq
      ansible.builtin.service:
        name: NetworkManager
        state: restarted
      when: dnsmasq.changed
      become: true

    - name: Restart libvirt when configuring dnsmasq
      ansible.builtin.service:
        name: libvirtd
        state: restarted
      when: dnsmasq.changed
      become: true

    - name: Adding master mac on DHCP when SNO
      community.libvirt.virt_net:
        name: "{{ kvmnetwork }}"
        command: modify
        xml: "<host mac='{{ master0infosno.stdout }}' ip='{{ master0ip.stdout_lines | first }}'/>"
      register: master0infosno
      become: true
      when: sno == "true"

    - name: Adding lb and masters mac on DHCP when 3-node
      community.libvirt.virt_net:
        name: "{{ kvmnetwork }}"
        command: modify
        xml: "<host mac='{{ item.mac }}' ip='{{ item.ip }}'/>"
      register: allmacsinfo
      become: true
      with_items:
        - { mac: "{{ lb_info.stdout }}", ip: "{{ lbvip.stdout_lines | first }}" }
        - { mac: "{{ master0info.stdout }}", ip: "{{ master0ip.stdout_lines | first }}" }
        - { mac: "{{ master1info.stdout }}", ip: "{{ master1ip.stdout_lines | first }}" }
        - { mac: "{{ master2info.stdout }}", ip: "{{ master2ip.stdout_lines | first }}" }
      when: sno == "false"
      ignore_errors: true

    - name: Copy haproxy.cfg to lb
      ansible.builtin.template:
        src: "haproxy.cfg-kvm.j2"
        dest: "/etc/haproxy/haproxy.cfg"
        mode: "0644"
      delegate_to: "{{ lbvip.stdout_lines | first }}"
      remote_user: "root"
      when: sno == "false"

    - name: Restart haproxy on LB
      ansible.builtin.systemd:
        name: haproxy
        state: restarted
        enabled: false
      delegate_to: "{{ lbvip.stdout_lines | first }}"
      remote_user: "root"
      when: sno == "false"

    - name: Waiting for RHCOS Installation to finish on bootstrap
      ansible.builtin.shell: "virsh list --name |  { grep -E '{{ clustername }}-master|{{ clustername }}-worker|{{ clustername }}-bootstrap' || true; }"
      retries: 600
      delay: 5
      become: true
      register: vms
      until: vms.stdout == ""
      when: sno == "false"

    - name: Add extra disks on master when install ODF
      ansible.builtin.blockinfile:
        path: "/etc/libvirt/qemu/{{ clustername }}-{{ item }}.xml"
        marker: "<!-- {mark} ANSIBLE MANAGED BLOCK -->"
        insertafter: "  <devices>$"
        block: |
          <disk type="file" device="disk">
            <driver name="qemu" type="qcow2" cache="none"/>
            <source file="{{ clusters_dir }}/{{ clustername }}/{{ clustername }}-{{ item }}-extra-disk.qcow2"/>
            <target dev="vdb" bus="virtio"/>
          </disk>
      loop:
        - "master-0"
        - "master-1"
        - "master-2"
      register: extra_disks_result
      become: true
      changed_when: true
      when: installodf == "true" and sno == "false"

    - name: Restart libvirt when configuring dnsmasq
      ansible.builtin.service:
        name: libvirtd
        state: restarted
      become: true

    - name: Starting virtual machines when 3-node cluster
      ansible.builtin.command: "virsh start {{ clustername }}-{{ item }}"
      register: startsnovms
      changed_when: startsnovms.rc == 0
      become: true
      with_items:
        - "bootstrap"
        - "master-0"
        - "master-1"
        - "master-2"
      when: sno == "false"

    - name: Define KVM Workers
      ansible.builtin.command: virt-install  --import --name {{ clustername }}-worker-{{ item }}   \
            --disk {{ clusters_dir }}/{{ clustername }}/{{ clustername }}-worker-{{ item }}.qcow2,bus=virtio,size=120 \
            --disk {{ clusters_dir }}/{{ clustername }}/rhcos-worker.iso,device=cdrom \
            --boot hd,cdrom --check path_in_use=off --noautoconsole \
            --ram {{ worker_mem }} --cpu host --vcpus {{ worker_cpu }} --os-variant rhel9-unknown --network network={{ kvmnetwork }},model=virtio \
      register: createworkers
      args:
        chdir: "{{ clusters_dir }}/{{ clustername }}"
      changed_when: createworkers.rc == 0
      with_sequence: count={{ n_worker }} start=0
      when: n_worker != 0 and installocpvirt != "true"
      become: true

    - name: Define KVM Workers when install OCP Virt
      ansible.builtin.command: virt-install  --import --name {{ clustername }}-worker-{{ item }}   \
            --disk {{ clusters_dir }}/{{ clustername }}/{{ clustername }}-worker-{{ item }}.qcow2,bus=virtio,size=120 \
            --disk {{ clusters_dir }}/{{ clustername }}/rhcos-worker.iso,device=cdrom \
            --boot hd,cdrom --check path_in_use=off --noautoconsole \
            --ram {{ worker_mem }} --cpu host --vcpus {{ worker_cpu }} --os-variant rhel9-unknown \
            --network network={{ kvmnetwork }},model=virtio --network bridge=br1,model=virtio \
      register: createworkers
      args:
        chdir: "{{ clusters_dir }}/{{ clustername }}"
      changed_when: createworkers.rc == 0
      with_sequence: count={{ n_worker }} start=0
      when: n_worker != 0 and installocpvirt == "true"
      become: true

    - name: Wait for the worker VM's to get an IP address
      ansible.builtin.shell: "virsh domifaddr {{ clustername }}-worker-{{ item }} | grep ipv4 | awk '{print $4}' | cut -d'/' -f1"
      retries: "180"
      delay: "3"
      until: workerip.stdout is defined and workerip.stdout != ""
      register: workerip
      with_sequence: count={{ n_worker }} start=0
      when: n_worker != 0
      become: true

    - name: Get a list of all virtual machines
      ansible.builtin.command: virsh list --all --name
      register: vms
      changed_when: vms.rc == 0
      become: true

    #  TODO: fix
    - name: Filter VMs containing 'worker' in their names
      ansible.builtin.set_fact:
        worker_vms: "{{ vms.stdout_lines | select('search', 'worker') }}"
      when: n_worker != 0
      become: true

    - name: Gather MAC addresses of VMs
      ansible.builtin.command: virsh domifaddr {{ item }}
      loop: "{{ worker_vms }}"
      register: vm_interfaces
      changed_when: vm_interfaces.rc == 0
      when: n_worker != 0
      become: true

    - name: Extract MAC addresses from interface information
      ansible.builtin.set_fact:
        mac_addresses: "{{ mac_addresses | default([]) + [item.stdout | regex_findall('([\\w:]{17})')] }}"
        worker_ips: "{{ worker_ips | default([]) + [item.stdout | regex_findall('\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}')] }}"
      loop: "{{ vm_interfaces.results }}"
      when: n_worker != 0
      become: true

    - name: Adding worker mac on DHCP
      community.libvirt.virt_net:
        name: "{{ kvmnetwork }}"
        command: modify
        xml: "<host mac='{{ mac_addresses[item | int ] | first }}' ip='{{ worker_ips[item | int] | first }}'/>"
      register: worker_info
      with_sequence: count={{ n_worker }} start=0
      when: n_worker != 0
      become: true

    - name: Adding worker names on dhcp
      ansible.builtin.lineinfile:
        path: "/etc/dnsmasq.{{ clustername }}.addnhosts"
        line: '{{ worker_ips[item | int] | first }} {{ clustername }}-worker-{{ item }}.{{ basedomain }}'
        state: present
      register: dhcpname
      with_sequence: count={{ n_worker }} start=0
      when: n_worker != 0
      become: true

    - name: Restart Network Manager when configuring dnsmasq
      ansible.builtin.service:
        name: NetworkManager
        state: restarted
      become: true

    - name: Restart libvirt when configuring dnsmasq
      ansible.builtin.service:
        name: libvirtd
        state: restarted
      become: true

    - name: Getting user group name
      ansible.builtin.command:
        cmd: 'id -gn'
      register: usergroup
      changed_when: usergroup.rc == 0

    - name: Change owner and group on clusters_dir
      ansible.builtin.file:
        path: "{{ clusters_dir }}"
        owner: "{{ lookup('env', 'USER') }}"
        group: "{{ usergroup.stdout }}"
        recurse: true
        state: directory
      become: true

    - name: Sleeping for 20 minutes before to check if cluster has been installed
      ansible.builtin.pause:
        minutes: 20
      when: n_worker == 0

    - name: Wait for SSH to be available on the worker node
      ansible.builtin.wait_for:
        host: "{{ worker_ips[item | int] | first }}"
        port: 22
        timeout: 3600
        state: started
        sleep: 10
      with_sequence: count={{ n_worker }} start=0
      when: n_worker != 0

    - name: Copy worker.ign to worker nodes
      ansible.builtin.copy:
        src: "{{ clusters_dir }}/{{ clustername }}/worker.ign"
        dest: "/var/home/core/worker.ign"
        mode: "0644"
      delegate_to: "{{ worker_ips[item | int] | first }}"
      with_sequence: count={{ n_worker }} start=0
      remote_user: "core"
      when: n_worker != 0
      vars:
        ansible_ssh_user: core

    - name: Execute coreos-installer on worker nodes
      ansible.builtin.shell:
        cmd: "coreos-installer install --ignition-file=/var/home/core/worker.ign /dev/vda"
      delegate_to: "{{ worker_ips[item | int] | first }}"
      with_sequence: count={{ n_worker }} start=0
      remote_user: "core"
      become: true
      when: n_worker != 0
      vars:
        ansible_ssh_user: core

    - name: Rebooting worker nodes
      ansible.builtin.reboot:
        reboot_timeout: 300
      delegate_to: "{{ worker_ips[item | int] | first }}"
      with_sequence: count={{ n_worker }} start=0
      remote_user: "core"
      become: true
      when: n_worker != 0
      vars:
        ansible_ssh_user: core

    - name: Add ODF labels on nodes when upi
      kubernetes.core.k8s:
        kubeconfig: "{{ clusters_dir }}/{{ clustername }}/auth/kubeconfig"
        definition:
          apiVersion: v1
          kind: Node
          metadata:
            name: "{{ clustername }}-{{ item }}.{{ basedomain }}"
            labels:
              cluster.ocs.openshift.io/openshift-storage: ""
              node-role.kubernetes.io/infra: ""
              node-role.kubernetes.io/master: ""
              node-role.kubernetes.io/worker: ""
              node-role.kubernetes.io/control-plane: ""
              beta.kubernetes.io/arch: amd64
              beta.kubernetes.io/os: linux
              kubernetes.io/arch: amd64
              kubernetes.io/hostname: "{{ clustername }}-{{ item }}.{{ basedomain }}"
              kubernetes.io/os: linux
              node.openshift.io/os_id: rhcos
      loop:
        - "master-0"
        - "master-1"
        - "master-2"
      retries: 60
      delay: 10
      register: resultodfnodes
      failed_when: resultodfnodes is failed or resultodfnodes.failed
      when: installodf == "true" and sno == "false"

    - name: Creating CSR Approver manifests
      kubernetes.core.k8s:
        kubeconfig: "{{ clusters_dir }}/{{ clustername }}/auth/kubeconfig"
        state: present
        template: "{{ item }}.yaml.j2"
      loop:
        - csr-approver-ns
        - csr-approver-sa
        - csr-approver-cr
        - csr-approver-crb
        - csr-approver-rb
        - csr-approver-cronjob
      register: result
      until: result is succeeded
      retries: 60
      delay: 10
      failed_when: result is failed or result.failed
      when: n_worker != 0

    - name: Run wait-for bootstrap-complete
      ansible.builtin.command: "./openshift-install wait-for bootstrap-complete"
      args:
        chdir: "{{ clusters_dir }}/{{ clustername }}"
      async: 3600
      poll: 0
      register: waitbootstrap
      changed_when: true
      when: sno == "false"

    - name: Check if bootstrap vm can be removed
      ansible.builtin.async_status:
        jid: "{{ waitbootstrap.ansible_job_id }}"
      register: job_result
      until: job_result.finished
      delay: 10
      retries: 600
      when: sno == "false"

    - name: Remove bootstrap VM
      community.libvirt.virt:
        name: "{{ clustername }}-bootstrap"
        state: destroyed
      when: sno == "false"
      become: true

    - name: Undefine bootstrap VM
      community.libvirt.virt:
        name: "{{ clustername }}-bootstrap"
        command: undefine
        force: true
      when: sno == "false"
      become: true

    - name: Set the number of replicas for the 'default' ingresscontroller to 3
      kubernetes.core.k8s:
        kubeconfig: "{{ clusters_dir }}/{{ clustername }}/auth/kubeconfig"
        api_version: operator.openshift.io/v1
        kind: IngressController
        namespace: openshift-ingress-operator
        name: default
        state: present
        definition:
          spec:
            replicas: 3
      register: resultingress
      until: resultingress is succeeded
      retries: 60
      delay: 10
      failed_when: result is failed or resultingress.failed
      when: sno == "false"

    - name: Check and wait for CRD LocalVolumeDiscovery
      kubernetes.core.k8s_info:
        kubeconfig: "{{ clusters_dir }}/{{ clustername }}/auth/kubeconfig"
        kind: CustomResourceDefinition
        api_version: apiextensions.k8s.io/v1
        name: localvolumediscoveries.local.storage.openshift.io
      register: crd_info
      retries: 60
      delay: 10
      until: crd_info.resources is defined
      ignore_errors: true
      when: installodf == "true" and sno == "false"

    - name: Configuring LSO
      kubernetes.core.k8s:
        kubeconfig: "{{ clusters_dir }}/{{ clustername }}/auth/kubeconfig"
        state: present
        template: '{{ item }}'
      loop:
        - local-storage-localvolumeset.yaml.j2
        - local-storage-localvolumediscovery.yaml.j2
      register: resultlso
      until: resultlso is succeeded
      retries: 60
      delay: 10
      failed_when: resultlso is failed or resultlso.failed
      when: installodf == "true" and sno == "false"

    - name: Check and wait for CRD to ODF
      kubernetes.core.k8s_info:
        kubeconfig: "{{ clusters_dir }}/{{ clustername }}/auth/kubeconfig"
        kind: CustomResourceDefinition
        api_version: apiextensions.k8s.io/v1
        name: storagesystems.odf.openshift.io
      register: crd_sto_info
      retries: 10
      delay: 30
      until: crd_sto_info.resources is defined
      ignore_errors: true
      when: installodf == "true" and sno == "false"

    - name: Configuring ODF operator
      kubernetes.core.k8s:
        kubeconfig: "{{ clusters_dir }}/{{ clustername }}/auth/kubeconfig"
        state: present
        template: '{{ item }}'
      loop:
        - odf-storagecluster.yaml.j2
        - odf-storagesystem.yaml.j2
      register: resultodf
      until: resultodf is succeeded
      retries: 60
      delay: 10
      failed_when: resultodf is failed or resultodf.failed
      when: installodf == "true" and sno == "false"

    - name: Configuring OCP Virt Hyperconverged
      kubernetes.core.k8s:
        kubeconfig: "{{ clusters_dir }}/{{ clustername }}/auth/kubeconfig"
        state: present
        template: ocpvirt-hyperconverged.yaml.j2
      register: resulthc
      until: resulthc is succeeded
      retries: 60
      delay: 10
      failed_when: resulthc is failed or resulthc.failed
      when: installodf == "true" and installocpvirt == "true" and sno == "false"

    - name: Wait StorageClass ocs-storagecluster-ceph-rbd
      kubernetes.core.k8s_info:
        kubeconfig: "{{ clusters_dir }}/{{ clustername }}/auth/kubeconfig"
        api_version: storage.k8s.io/v1
        kind: StorageClass
        name: ocs-storagecluster-ceph-rbd
      register: storageclass_info
      retries: 30
      delay: 10
      until: storageclass_info.resources is defined
      ignore_errors: true
      when: installodf == "true" and installodf == "true" and sno == "false"

    - name: Mark the StorageClass ocs-storagecluster-ceph-rbd as the default
      kubernetes.core.k8s:
        kubeconfig: "{{ clusters_dir }}/{{ clustername }}/auth/kubeconfig"
        state: patched
        kind: StorageClass
        name: ocs-storagecluster-ceph-rbd
        merge_type: strategic-merge
        definition:
          metadata:
            annotations:
              storageclass.kubernetes.io/is-default-class: "true"
      register: resultsc
      until: resultsc is succeeded
      retries: 60
      delay: 10
      failed_when: resultsc is failed or resultsc.failed
      when: installodf == "true" and installodf == "true" and sno == "false"

    - name: Run wait-for install-complete
      ansible.builtin.command: "./openshift-install wait-for install-complete"
      args:
        chdir: "{{ clusters_dir }}/{{ clustername }}"
      async: 3600
      poll: 0
      register: install
      changed_when: true

    - name: Check if the cluster has been installed
      ansible.builtin.async_status:
        jid: "{{ install.ansible_job_id }}"
      register: job_result
      until: job_result.finished
      delay: 10
      retries: 600

    - name: Create the HTPasswd file with admin user
      community.general.htpasswd:
        path: "{{ clusters_dir }}/{{ clustername }}/auth/users.htpasswd"
        name: "{{ admin_user }}"
        password: "{{ htpasswd_pass }}"
        owner: "{{ lookup('env', 'USER') }}"
        mode: "0640"
        create: true
      when: admin_user != ""

    - name: Create secret with HTPasswd data in OpenShift
      kubernetes.core.k8s:
        kubeconfig: "{{ clusters_dir }}/{{ clustername }}/auth/kubeconfig"
        state: present
        definition:
          apiVersion: v1
          kind: Secret
          metadata:
            name: htpass-secret
            namespace: openshift-config
          data:
            htpasswd: "{{ lookup('file', clusters_dir + '/' + clustername + '/auth/users.htpasswd') | b64encode }}"
          type: Opaque
      when: admin_user != ""

    - name: Configure HTPasswd identity provider
      kubernetes.core.k8s:
        kubeconfig: "{{ clusters_dir }}/{{ clustername }}/auth/kubeconfig"
        state: present
        definition:
          apiVersion: config.openshift.io/v1
          kind: OAuth
          metadata:
            name: cluster
          spec:
            identityProviders:
            - name: htpasswd_provider
              mappingMethod: claim
              type: HTPasswd
              htpasswd:
                fileData:
                  name: htpass-secret
      register: htpasswdprovider
      when: admin_user != ""

    - name: Wait Until Authentication Operator start rollout
      kubernetes.core.k8s_info:
        kubeconfig: "{{ clusters_dir }}/{{ clustername }}/auth/kubeconfig"
        validate_certs: false
        kind: ClusterOperator
        name: authentication
        wait: true
        wait_condition:
          type: Progressing
          status: true
        wait_timeout: 600
      when: htpasswdprovider.changed and admin_user != ""

    - name: Wait Until Authentication be ready
      kubernetes.core.k8s_info:
        kubeconfig: "{{ clusters_dir }}/{{ clustername }}/auth/kubeconfig"
        validate_certs: false
        kind: ClusterOperator
        name: authentication
        wait: true
        wait_condition:
          type: Progressing
          status: false
        wait_timeout: 600
      when: htpasswdprovider.changed and admin_user != ""

    - name: Grant cluster-admin role to the new admin user
      kubernetes.core.k8s:
        kubeconfig: "{{ clusters_dir }}/{{ clustername }}/auth/kubeconfig"
        state: present
        definition:
          apiVersion: rbac.authorization.k8s.io/v1
          kind: ClusterRoleBinding
          metadata:
            name: cluster-admin-{{ admin_user }}
          subjects:
            - kind: User
              name: "{{ admin_user }}"
              apiGroup: rbac.authorization.k8s.io
          roleRef:
            kind: ClusterRole
            name: cluster-admin
            apiGroup: rbac.authorization.k8s.io
      when: admin_user != ""

    - name: Remove kubeadmin user
      kubernetes.core.k8s:
        kubeconfig: "{{ clusters_dir }}/{{ clustername }}/auth/kubeconfig"
        state: absent
        kind: Secret
        name: kubeadmin
        namespace: kube-system
      when: remove_kubeadmin_user == "true" and admin_user != ""

    - name: Wait for worker nodes to be ready
      kubernetes.core.k8s_info:
        kind: Node
        kubeconfig: "{{ clusters_dir }}/{{ clustername }}/auth/kubeconfig"
        name: "{{ clustername }}-worker-{{ item }}.{{ basedomain }}"
      register: nodes_info
      retries: 120
      delay: 10
      until:
        - nodes_info.resources[0].status is defined
        - nodes_info.resources[0].status.conditions is defined
        - (nodes_info.resources[0].status.conditions | selectattr('type', 'equalto', 'Ready'))
        - (nodes_info.resources[0].status.conditions | selectattr('reason', 'equalto', 'KubeletReady'))
      with_sequence: count={{ n_worker }} start=0
      when: n_worker != 0

    - name: Pause cronjob ocp-csr-approver
      kubernetes.core.k8s:
        kubeconfig: "{{ clusters_dir }}/{{ clustername }}/auth/kubeconfig"
        state: present
        definition:
          apiVersion: batch/v1
          kind: CronJob
          metadata:
            name: "ocp-csr-approver"
            namespace: "ocp-csr-approver"
          spec:
            suspend: true
      when: n_worker != 0

    - name: Copying create-tmuxp.yaml file
      ansible.builtin.template:
        src: create-tmuxp.yaml.j2
        dest: "{{ clusters_dir }}/{{ clustername }}/create-tmuxp.yaml"
        mode: '0644'
      register: copy_create_tmuxp
      retries: 10
      delay: 5
      failed_when: copy_create_tmuxp is failed
      until: copy_create_tmuxp is succeeded

    - name: Copying upgrade-tmuxp.yaml file
      ansible.builtin.template:
        src: upgrade-tmuxp.yaml.j2
        dest: "{{ clusters_dir }}/{{ clustername }}/upgrade-tmuxp.yaml"
        mode: '0644'
      register: copy_upgrade_tmuxp
      retries: 10
      delay: 5
      failed_when: copy_create_tmuxp is failed
      until: copy_upgrade_tmuxp is succeeded

    - name: Copying clustername.json template file
      ansible.builtin.template:
        src: clustername.json.j2
        dest: "{{ clusters_dir }}/{{ clustername }}/{{ clustername }}.json"
        mode: '0644'
      register: copy_clustername_json
      retries: 10
      delay: 5
      failed_when: copy_clustername_json is failed
      until: copy_clustername_json is succeeded

    - name: Collect the end time
      ansible.builtin.set_fact:
        end_time: "{{ lookup('pipe', 'date +%s') }}"

    - name: Calculate the script execution time
      ansible.builtin.set_fact:
        total_time: "{{ (end_time | int) - (start_time | int) }}"

    - name: Convert the execution time to hour, minute and seconds
      ansible.builtin.set_fact:
        hours: "{{ (total_time | int) // 3600 }}"
        minutes: "{{ ((total_time | int) % 3600) // 60 }}"
        seconds: "{{ (total_time | int) % 60 }}"

    - name: Show the script execution time
      ansible.builtin.debug:
        msg: "The execution time is {{ hours }}h {{ minutes }}m {{ seconds }}s."
